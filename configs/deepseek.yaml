# _model_options = (
#     "DeepSeek-R1-Distill-Qwen-1.5B",
#     "DeepSeek-R1-Distill-Qwen-7B",
#     "DeepSeek-R1-Distill-Llama-8B",
#     "DeepSeek-R1-Distill-Qwen-14B",
#     "QwQ-32B",
# )


mode: "local"  # options: {local, api}
frame: "transformers"  # options: {transformers, vllm}
model_name: "DeepSeek-R1-Distill-Qwen-14B"
role: "tieba_maoniang"
history: 3

model_config:
  rag: True
  transformers:
    torch_dtype: "auto"
    max_token: 512
    num_beams: 1  # num_beams=1 禁用束搜索
    do_sample: False  # 禁用采样
    use_cache: True  # 启用KV cache
    use_streamer: True